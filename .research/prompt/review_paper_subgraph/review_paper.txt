
Input:
You are an expert reviewer for a top-tier international conference.
Please conduct a comprehensive review of the research paper provided, evaluating it according to the standards of venues like NeurIPS, ICML, ICLR, or AAAI.

Your task is to evaluate the paper on four key dimensions and provide scores from 1-10 for each:

## Evaluation Dimensions:

### 1. Novelty (1-10)
- How original and innovative is the proposed approach?
- Does it introduce new concepts, methods, or insights?
- Is there sufficient differentiation from existing work?

### 2. Significance (1-10)
- What is the potential impact of this work on the field?
- Does it address an important problem?
- Are the contributions meaningful and substantial?

### 3. Reproducibility (1-10)
- Are the experimental details sufficient for reproduction?
- Is the methodology clearly described?
- Are datasets, hyperparameters, and implementation details provided?

### 4. Experimental Quality (1-10)
- Are the experiments well-designed and comprehensive?
- Are appropriate baselines and evaluation metrics used?
- Is statistical significance properly assessed?
- Are the results convincing and well-analyzed?

## Section-by-Section Analysis:

For each section of the paper, provide:
- Key strengths
- Areas for improvement
- Specific comments on quality and completeness

## Overall Assessment:

Provide your scores for each dimension, followed by an overall recommendation.

## Paper Content:


**Title:** Adaptive Tail Weighting for Bayesian Optimization of Iterative Learning


**Abstract:** Bayesian Optimization for Iterative Learning (BOIL) accelerates hyper-parameter search by feeding a Gaussian process with a single scalar obtained from each training curve. That scalar is produced with a fixed logistic weighting of intermediate observations. Unfortunately, the fixed weights can over-emphasise noisy early iterations or under-value stable late progress, degrading surrogate fidelity in highly non-stationary settings such as deep reinforcement learning. We introduce Adaptive-Tail-Weighted BOIL (ATW-BOIL), a drop-in replacement that learns one additional exponent α≥0 so the compression smoothly tilts toward later, more reliable points. The new score is sα = Σt w t(α)·y t / Σt w t(α) with weights w t(α)=((t/T)+ε)^α·σ(g( t/T − m )). We optimise α jointly with the original logistic midpoint m and growth g by maximising GP marginal likelihood; every other component of BOIL—surrogate, cost-aware acquisition, and virtual observations—remains untouched. Across CartPole-v1, CIFAR-10 and WikiText-2, ATW-BOIL lifts the area-under-best-seen-score curve by roughly 16 % and cuts time-to-target by 17–22 % at only 2.5 % extra overhead. Robustness experiments on Pong, ImageNet-mini and Humanoid confirm consistent gains, improved surrogate calibration, and adaptive α values that correlate with curve noise. A single learned tail weight therefore yields a more trustworthy target for Bayesian optimisation and measurably accelerates hyper-parameter search without complicating the existing framework.


**Introduction:** Hyper-parameter optimisation (HPO) remains a major cost driver in modern machine learning. Bayesian Optimisation for Iterative Learning (BOIL) showed that the intermediate trajectory of a training run can be compressed into a single scalar that feeds a Gaussian-process (GP) surrogate, while a cost-aware acquisition decides how long to continue training [nguyen-2019-bayesian]. BOIL’s fixed logistic weighting succeeds on many tasks, yet in highly non-stationary or noisy environments—particularly deep reinforcement learning (RL)—early rewards fluctuate wildly. When those volatile points receive too much emphasis, the compressed target becomes noisy, the GP posterior mis-calibrates, and acquisition decisions slow the search.

We ask a focused question: can curve compression become mildly more adaptive, with no changes to kernels, acquisition rules, or virtual observations, so the surrogate more faithfully represents eventual performance? Adaptive-Tail-Weighted BOIL (ATW-BOIL) answers yes by adding one learnable exponent α≥0. The modified weight w t(α)=((t/T)+ε)^α·σ(g(τ_t−m))—where τ_t=t/T and σ is the logistic sigmoid—retains BOIL’s preference for fast early learning but lets data decide how much to discount unstable beginnings. Joint optimisation of α, the logistic midpoint m and growth g under GP marginal likelihood keeps computational cost negligible and guarantees backwards compatibility: α=0 exactly reproduces BOIL.

Beyond BOIL, alternative HPO paradigms such as neural-network partitioning pursue validation-free marginal-likelihood surrogates [mlodozeniec-2023-hyperparameter]. Those methods alter the optimisation objective, whereas ATW-BOIL stays within the conventional BO loop and simply refines the curve-to-scalar mapping, making it easy to deploy in existing BOIL pipelines.

Comprehensive experiments demonstrate that this single extra degree of freedom is worthwhile. On CartPole-v1, ATW-BOIL reaches the solved threshold 22 % sooner and achieves a slightly higher final reward within an identical compute budget. Similar improvements arise on CIFAR-10 image classification and WikiText-2 language modelling. A second study on Pong, ImageNet-mini and MuJoCo Humanoid confirms robustness: the learned α rises on noisy tasks (≈1.4) and stays low on stable ones (≈0.3), surrogate negative log-likelihood (NLL) drops, and wall-clock overhead is only 2.5 % per iteration.

Contributions
• We introduce a minimal yet principled extension to BOIL that learns an adaptive tail-weight exponent α≥0 through GP marginal likelihood.
• We connect tail weighting to a Bayesian variance prior on curve observations, offering an interpretable mechanism that discounts early noise while rewarding rapid learning.
• We provide an empirical study across six tasks showing 16 % higher area-under-best-seen-score and 17–22 % faster time-to-target, with better surrogate calibration and negligible computational cost.
• Ablation analyses confirm that learning α is critical and that tail weighting complements, rather than replaces, BOIL’s logistic gate.

Future work includes contextual or feature-based α, task-conditional priors, integration with multi-fidelity schedulers, and coupling to more expressive surrogates, all enabled by the drop-in nature of ATW-BOIL.


**Related Work:** Curve-aware Bayesian optimisation methods fall into two broad classes. The first, exemplified by BOIL, compresses a learning curve into a scalar target and applies standard GP-based BO with cost-aware acquisitions [nguyen-2019-bayesian]. BOIL’s logistic weighting balances rapid early progress against late stability but is fixed once its parameters are learned, potentially mis-weighting very noisy starts. ATW-BOIL amends only this compression stage, leaving surrogate and decision logic untouched.

The second class models the temporal dimension explicitly. Freeze-Thaw and Learning-Curve-BO fit parametric or kernel-based curve models, while bandit schedulers such as Hyperband and ASHA allocate budget based on partial training results. These approaches often achieve strong wall-clock efficiency but either lack calibrated uncertainty (bandits) or introduce significant model complexity (parametric curves). ATW-BOIL instead preserves BOIL’s simplicity: a GP over hyper-parameters, no temporal kernels, and cost-aware expected improvement—changing only how the target s(x) is produced.

Validation-free methods pursue different objectives. Neural network partitioning, for instance, optimises hyper-parameters by approximating marginal likelihood without held-out data [mlodozeniec-2023-hyperparameter]. While computationally attractive, those methods re-define the optimisation goal and training protocol. In contrast, ATW-BOIL maintains the standard validation-driven workflow and is therefore complementary: its adaptive compression could feed into more sophisticated surrogates or combine with validation-free objectives in hybrid schemes.

Relative to BOIL, our contribution specifically relaxes the assumption that a single logistic gate can express reliability across diverse curve shapes. By introducing α≥0 and learning it alongside logistic parameters, ATW-BOIL adapts emphasis between early and late iterations, improving surrogate fidelity especially when early noise is high.


**Background:** We study hyper-parameter optimisation for iterative learners that output a sequence of performance measurements y₁,…,y_T. BOIL transforms each curve into a scalar score s(x) via a logistic weighting, then fits a Gaussian process f(x)≈s(x) over the hyper-parameter space. A cost-aware expected-improvement acquisition selects both the next configuration and the amount of additional training, while virtual observations allow partial curves to enter the dataset at controlled cost [nguyen-2019-bayesian].

Formally, let τ_t = t/T denote normalised time. BOIL’s weights are w_t = σ(g(τ_t−m)), where σ is the logistic sigmoid and m, g are learned by maximising GP marginal likelihood. The compressed score is s = Σ_t w_t y_t / Σ_t w_t. This scheme rewards fast initial improvement through the rising flank of the sigmoid while emphasising stability once τ_t exceeds m.

Limitation. Because w_t depends only on τ_t through a fixed sigmoid, all curves receive identical relative emphasis regardless of noise profile. In RL, early returns often have large variance; placing substantial mass on those points injects noise into s, which the GP must model as observation error. A noisier surrogate reduces acquisition confidence and slows optimisation.

Motivation for tail weighting. Later parts of a training curve typically have lower variance and better predict asymptotic performance. We therefore introduce an exponent α≥0 to discount early points according to a simple power law: w_t(α)=((τ_t+ε))^α·σ(g(τ_t−m)). When α=0 the original BOIL compression is recovered; α>0 progressively downweights early iterations. Because α is learned from data, the model automatically adapts to the empirical variance structure of each task, improving the signal-to-noise ratio of the target s_α.

Assumptions. We assume that later observations are, on average, at least as informative as earlier ones—a mild condition satisfied by most monotone or saturating learning curves. No further assumptions are made; all other BOIL mechanics remain in place, ensuring that ATW-BOIL can be adopted without re-engineering.


**Method:** Adaptive-Tail-Weighted BOIL modifies the curve-to-scalar mapping while leaving the wider BO pipeline intact.

Compression function. For a curve y and normalised time τ_t=t/T we define
w_t(α)=((τ_t+ε))^α·σ(g(τ_t−m)), s_α=Σ_t w_t(α)·y_t / Σ_t w_t(α),
where ε=10⁻⁹ avoids zero weight at τ_t=0, m is the logistic midpoint and g its growth. The exponent α≥0 smoothly tilts mass toward the tail; α=0 yields BOIL exactly.

Parameter learning. Let D={(x_i,s_i)} be the dataset of compressed scores at a given BO iteration. We maximise the GP log marginal likelihood L(θ,ψ|D) with respect to θ={m,g,α} and GP hyper-parameters ψ. Gradients of s_α with respect to θ are computed via automatic differentiation over the soft weights w_t, so optimisation adds negligible overhead: one extra scalar dimension and no additional passes over curves.

Integration with BOIL. Once θ is updated, curves observed so far are re-compressed to produce s_i, the GP is refitted, and cost-aware expected improvement proposes the next (x,budget) pair. Virtual observations and sparse GP options remain exactly as in the original implementation [nguyen-2019-bayesian]. Computing s_α scales linearly with T and is often dominated by simulation or training time, making ATW-BOIL virtually free.

Regularisation. To avoid degeneracy between parameters we bound α∈[0,3] and initialise it at 0. Empirically α converges after 8–12 BO iterations and shifts only when the noise characteristics of candidate curves change.

Interpretation. Weighting by (τ_t+ε)^α is equivalent to assuming observation variance Var[y_t]∝(τ_t+ε)^{−2α}, giving later points lower variance in a Bayesian sense. This improves GP calibration, which in turn yields more reliable acquisition values and faster convergence.

Algorithm summary.
1 Initialise GP hyper-parameters and θ=(m,g,α=0).
2 For each BO iteration:
  a Compress all available curves with current θ to obtain s.
  b Fit or update GP on (x,s).
  c Select next configuration and training budget via cost-aware EI.
  d Run training for the selected budget; log the curve.
  e Update θ and GP hyper-parameters by maximising marginal likelihood.
3 Return the best hyper-parameter configuration found within the compute budget.


**Experimental Setup:** We follow the experimental strategy outlined in the context, executing two studies.

Study 1 (exp-1-main-multitask). Tasks: CartPole-v1 (Dueling DQN), CIFAR-10 classification, WikiText-2 language modelling. Search spaces mirror those in the original BOIL paper; for CartPole, learning rate ∈[10⁻⁴,10⁻²], discount γ∈[0.8,0.999], batch size ∈[32,256]. All methods—GP-EndScore, BOIL-Original, ATW-BOIL, ATW-fixed-α=0.5, ATW-noLogistic and Hyperband—receive identical wall-clock budgets: 3 GPU-hours for CartPole, 12 hours for CIFAR-10 and WikiText-2. Metrics: (i) area under the best-seen score versus time (AUC-T), (ii) time-to-reach task-specific thresholds (195 reward, 92 % validation accuracy, 34 perplexity), (iii) final performance at budget exhaustion. Five random seeds are run per task and per method.

Study 2 (exp-2-robustness-efficiency). Tasks: Atari Pong, ImageNet-mini and MuJoCo Humanoid-v4. These benchmarks exhibit higher noise or longer horizons, stressing robustness. Experimental protocol, baselines, budgets and metrics replicate Study 1 with ten seeds where feasible. Additional measurements include GP negative log-likelihood on held-out compressed scores, expected calibration error of posterior mean ±2σ, CPU time per BO iteration and memory footprint.

Implementation details. All code builds on the public BOIL repository, replacing only the transform_logistic function with a tail-weighted variant. Parameter bounds are m∈[0.2,0.8], g∈[1,15], α∈[0,3]. Optimisation uses Adam with learning rate 0.05 for θ and L-BFGS-B for GP hyper-parameters. Sparse GP with up to 2 048 inducing points is enabled for ImageNet-mini and Humanoid. Experiments run on identical NVIDIA 1080 Ti GPUs; CPU time is measured excluding training. Docker containers with fixed CUDA and PyTorch versions ensure reproducibility, and raw logs plus analysis notebooks are released.


**Results:** Optimisation quality. Across all six tasks ATW-BOIL consistently outperforms BOIL-Original. In Study 1 the mean AUC-T improvements are CartPole +19.2 %, CIFAR-10 +12.1 % and WikiText-2 +15.4 %, yielding an average gain of 15.6 % (Cohen’s d =0.81). Time-to-threshold drops by 22 %, 19 % and 17 % respectively; a paired Wilcoxon test over six measured targets gives p =2.6×10⁻⁴ after Holm–Bonferroni correction. Final performance at equal budget is slightly higher in every case: CartPole 199.2±0.5 vs 196.7±1.1 reward; CIFAR-10 93.4 %±0.3 vs 92.6 %±0.4 accuracy; WikiText-2 33.1±0.4 vs 34.6±0.5 perplexity.

Robustness and generality. Study 2 confirms gains in noisier regimes. ATW-BOIL reduces time-to-target by 22 % on Pong, 15 % on ImageNet-mini and 22 % on Humanoid. A robustness score measuring performance degradation under noise improves from 0.97±0.05 (BOIL) to 0.88±0.04 (lower is better), with a 73 % win-rate across 45 pairwise comparisons. Learned α adapts: median α≈1.4 on Pong where early variance is high, and α≈0.3 on CIFAR-10 where curves are smoother.

Surrogate metrics. GP NLL on held-out scores drops from 1.82±0.06 to 1.63±0.05, and calibration error within ±2σ falls from 0.14 to 0.09, indicating more trustworthy uncertainty. Sparse GP yields a 45 % memory reduction at <3 % AUC loss, demonstrating scalability.

Computational cost. Per-iteration wall-clock rises marginally: 1.21 s (BOIL) vs 1.24 s (ATW, +2.5 %). GPU memory overhead is <10 MB. Thus efficiency gains in optimisation far outweigh computational expense.

Ablation studies. Fixing α=0.5 captures only ~40 % of full benefit (AUC-T +7 %), proving the importance of learning α. Removing the logistic gate (ATW-noLogistic) loses 3 % AUC and harms robustness, showing that tail weighting and logistic emphasis act synergistically.

Fairness checks. All baselines share acquisition and virtual observations; search spaces, budgets and seeds are identical. Sensitivity analyses across budget scales and search-space sizes show stable improvements, with α typically converging within a dozen BO iterations.


**Conclusion:** ATW-BOIL demonstrates that a single adaptive tail-weight exponent is enough to make curve compression substantially more reliable for Bayesian optimisation. By learning how much to trust early versus late training observations, ATW-BOIL achieves around 16 % higher area-under-best-seen-score and 17–22 % faster time-to-target across six diverse tasks, while improving surrogate calibration and adding only negligible computational cost. Because the method leaves BOIL’s surrogate, acquisition and virtual-observation machinery untouched, it can be adopted with a one-line code change.

The study highlights the value of principled yet minimal modifications to existing frameworks. Future research can explore context-dependent or feature-based α, task-informed priors, integration with multi-fidelity schedulers, and coupling with more expressive surrogates. Given its simplicity and effectiveness, Adaptive-Tail-Weighted compression is a practical improvement for any system that already leverages BOIL for hyper-parameter optimisation.


Output:
{
    "novelty_score": 6,
    "significance_score": 7,
    "reproducibility_score": 8,
    "experimental_quality_score": 8
}
